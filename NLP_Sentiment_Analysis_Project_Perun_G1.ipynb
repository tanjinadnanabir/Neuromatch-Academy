{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM43YuHJKKDcWV6MQsprWR7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanjinadnanabir/Neuromatch-Academy/blob/main/NLP_Sentiment_Analysis_Project_Perun_G1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYsFBuFHaJYd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load and Explore Data ---\n",
        "try:\n",
        "    column = ['sentence','sentiment']\n",
        "    df = pd.read_csv('/content/sentences_sentiment.csv', names=column)\n",
        "    print(\"Dataset loaded successfully...\")\n",
        "    print(df.head())\n",
        "    df.info()\n",
        "    print(df['sentiment'].value_counts())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'sentences_sentiment.csv' not found...\")\n",
        "    exit()\n",
        "\n",
        "TEXT_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'sentiment'\n",
        "\n",
        "unique_sentiments = df[LABEL_COLUMN].unique()\n",
        "\n",
        "sentiment_to_int = {label: i for i, label in enumerate(sorted(unique_sentiments))}\n",
        "int_to_sentiment = {i: label for i, label in enumerate(sorted(unique_sentiments))}\n",
        "\n",
        "df[LABEL_COLUMN] = df[LABEL_COLUMN].map(sentiment_to_int)\n",
        "print(f\"\\nSentiment to integer mapping: {sentiment_to_int}\")\n",
        "print(f\"Integer to sentiment mapping: {int_to_sentiment}\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oaxi2NUWaeNl",
        "outputId": "2f3970d3-7467-4308-8b6b-d8ed3986224c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully...\n",
            "                                            sentence sentiment\n",
            "0  The Rock is destined to be the 21st Century 's...  POSITIVE\n",
            "1  The gorgeously elaborate continuation of `` Th...  POSITIVE\n",
            "2  Singer\\/composer Bryan Adams contributes a sle...  POSITIVE\n",
            "3  You 'd think by now America would have had eno...   NEUTRAL\n",
            "4               Yet the act is still charming here .  POSITIVE\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11853 entries, 0 to 11852\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sentence   11853 non-null  object\n",
            " 1   sentiment  11853 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 185.3+ KB\n",
            "sentiment\n",
            "POSITIVE    4963\n",
            "NEGATIVE    4649\n",
            "NEUTRAL     2241\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sentiment to integer mapping: {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}\n",
            "Integer to sentiment mapping: {0: 'NEGATIVE', 1: 'NEUTRAL', 2: 'POSITIVE'}\n",
            "                                            sentence  sentiment\n",
            "0  The Rock is destined to be the 21st Century 's...          2\n",
            "1  The gorgeously elaborate continuation of `` Th...          2\n",
            "2  Singer\\/composer Bryan Adams contributes a sle...          2\n",
            "3  You 'd think by now America would have had eno...          1\n",
            "4               Yet the act is still charming here .          2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocessing ---\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower() # Lowercase\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # URLs\n",
        "    text = re.sub(r'@\\w+', '', text) # mentions\n",
        "    text = re.sub(r'#\\w+', '', text) # hashtags\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) # punctuation and numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # extra whitespaces\n",
        "    return text\n",
        "\n",
        "df[TEXT_COLUMN] = df[TEXT_COLUMN].apply(preprocess_text)\n",
        "print(df.head())\n",
        "\n",
        "# Tokenization and Vocabulary Building\n",
        "\n",
        "all_words = []\n",
        "for text in df[TEXT_COLUMN]:\n",
        "    all_words.extend(text.split())\n",
        "\n",
        "word_counts = Counter(all_words)\n",
        "# Sort words by freq and alphabetic for order\n",
        "sorted_vocab = sorted(word_counts.items(), key=lambda x: (-x[1], x[0]))\n",
        "vocab_to_int = {word: i + 2 for i, (word, count) in enumerate(sorted_vocab)}\n",
        "\n",
        "vocab_to_int['<PAD>'] = 0 # Padding token\n",
        "vocab_to_int['<UNK>'] = 1 # Unknown word token\n",
        "\n",
        "int_to_vocab = {i: word for word, i in vocab_to_int.items()}\n",
        "\n",
        "print(f\"\\nVocab size: {len(vocab_to_int)}\")\n",
        "print(list(vocab_to_int.items())[:10])\n",
        "\n",
        "# text to num seq convertion\n",
        "def text_to_sequence(text, vocab_to_int):\n",
        "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]\n",
        "\n",
        "df['encoded_text'] = df[TEXT_COLUMN].apply(lambda x: text_to_sequence(x, vocab_to_int))\n",
        "print(df.head())\n",
        "\n",
        "# Max seq length for padding\n",
        "max_seq_len = max([len(seq) for seq in df['encoded_text']])\n",
        "print(f\"\\nMax sequence length: {max_seq_len}\")\n",
        "\n",
        "# Padding sequences\n",
        "def pad_sequence(sequence, max_len, pad_token):\n",
        "    if len(sequence) < max_len:\n",
        "        return sequence + [pad_token] * (max_len - len(sequence))\n",
        "    return sequence[:max_len] # Truncate if longer\n",
        "\n",
        "df['padded_encoded_text'] = df['encoded_text'].apply(lambda x: pad_sequence(x, max_seq_len, vocab_to_int['<PAD>']))\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXqcq-PUaqMg",
        "outputId": "1105c36e-ee35-4cb6-f062-b28dd45afbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            sentence  sentiment  \\\n",
            "0  the rock is destined to be the st century s ne...          2   \n",
            "1  the gorgeously elaborate continuation of the l...          2   \n",
            "2  singercomposer bryan adams contributes a slew ...          2   \n",
            "3  you d think by now america would have had enou...          1   \n",
            "4                 yet the act is still charming here          2   \n",
            "\n",
            "                                        encoded_text  \\\n",
            "0  [2, 607, 8, 2580, 6, 23, 2, 2471, 1160, 7, 99,...   \n",
            "1  [2, 3420, 2117, 7536, 5, 2, 4145, 5, 2, 3112, ...   \n",
            "2  [17181, 7347, 2265, 11525, 3, 17279, 5, 1384, ...   \n",
            "3  [21, 275, 239, 26, 326, 713, 85, 37, 204, 76, ...   \n",
            "4                    [173, 2, 593, 8, 117, 352, 139]   \n",
            "\n",
            "                                 padded_encoded_text  \n",
            "0  [2, 607, 8, 2580, 6, 23, 2, 2471, 1160, 7, 99,...  \n",
            "1  [2, 3420, 2117, 7536, 5, 2, 4145, 5, 2, 3112, ...  \n",
            "2  [17181, 7347, 2265, 11525, 3, 17279, 5, 1384, ...  \n",
            "3  [21, 275, 239, 26, 326, 713, 85, 37, 204, 76, ...  \n",
            "4  [173, 2, 593, 8, 117, 352, 139, 0, 0, 0, 0, 0,...  \n",
            "\n",
            "Vocab size: 19130\n",
            "[('the', 2), ('a', 3), ('and', 4), ('of', 5), ('to', 6), ('s', 7), ('is', 8), ('it', 9), ('that', 10), ('in', 11)]\n",
            "                                            sentence  sentiment  \\\n",
            "0  the rock is destined to be the st century s ne...          2   \n",
            "1  the gorgeously elaborate continuation of the l...          2   \n",
            "2  singercomposer bryan adams contributes a slew ...          2   \n",
            "3  you d think by now america would have had enou...          1   \n",
            "4                 yet the act is still charming here          2   \n",
            "\n",
            "                                        encoded_text  \\\n",
            "0  [2, 607, 8, 2580, 6, 23, 2, 2471, 1160, 7, 99,...   \n",
            "1  [2, 3420, 2117, 7536, 5, 2, 4145, 5, 2, 3112, ...   \n",
            "2  [17181, 7347, 2265, 11525, 3, 17279, 5, 1384, ...   \n",
            "3  [21, 275, 239, 26, 326, 713, 85, 37, 204, 76, ...   \n",
            "4                    [173, 2, 593, 8, 117, 352, 139]   \n",
            "\n",
            "                                 padded_encoded_text  \n",
            "0  [2, 607, 8, 2580, 6, 23, 2, 2471, 1160, 7, 99,...  \n",
            "1  [2, 3420, 2117, 7536, 5, 2, 4145, 5, 2, 3112, ...  \n",
            "2  [17181, 7347, 2265, 11525, 3, 17279, 5, 1384, ...  \n",
            "3  [21, 275, 239, 26, 326, 713, 85, 37, 204, 76, ...  \n",
            "4  [173, 2, 593, 8, 117, 352, 139, 0, 0, 0, 0, 0,...  \n",
            "\n",
            "Max sequence length: 52\n",
            "                                            sentence  sentiment  \\\n",
            "0  the rock is destined to be the st century s ne...          2   \n",
            "1  the gorgeously elaborate continuation of the l...          2   \n",
            "2  singercomposer bryan adams contributes a slew ...          2   \n",
            "3  you d think by now america would have had enou...          1   \n",
            "4                 yet the act is still charming here          2   \n",
            "\n",
            "                                        encoded_text  \\\n",
            "0  [2, 607, 8, 2580, 6, 23, 2, 2471, 1160, 7, 99,...   \n",
            "1  [2, 3420, 2117, 7536, 5, 2, 4145, 5, 2, 3112, ...   \n",
            "2  [17181, 7347, 2265, 11525, 3, 17279, 5, 1384, ...   \n",
            "3  [21, 275, 239, 26, 326, 713, 85, 37, 204, 76, ...   \n",
            "4                    [173, 2, 593, 8, 117, 352, 139]   \n",
            "\n",
            "                                 padded_encoded_text  \n",
            "0  [2, 607, 8, 2580, 6, 23, 2, 2471, 1160, 7, 99,...  \n",
            "1  [2, 3420, 2117, 7536, 5, 2, 4145, 5, 2, 3112, ...  \n",
            "2  [17181, 7347, 2265, 11525, 3, 17279, 5, 1384, ...  \n",
            "3  [21, 275, 239, 26, 326, 713, 85, 37, 204, 76, ...  \n",
            "4  [173, 2, 593, 8, 117, 352, 139, 0, 0, 0, 0, 0,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Dataset and DataLoader ---\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = torch.tensor(texts, dtype=torch.long)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # len of total num of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]\n",
        "\n",
        "# Split into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['padded_encoded_text'].tolist(),\n",
        "    df[LABEL_COLUMN].tolist(),\n",
        "    test_size=0.2, # 20% for test\n",
        "    random_state=42,\n",
        "    stratify=df[LABEL_COLUMN].tolist() # for maintaining balance class distribution\n",
        ")\n",
        "\n",
        "train_dataset = SentimentDataset(X_train, y_train)\n",
        "test_dataset = SentimentDataset(X_test, y_test)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Train:\", len(train_dataset))\n",
        "print(\"Test:\",len(test_dataset))\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))\n",
        "\n",
        "# Example batch from DataLoader\n",
        "# for texts, labels in train_loader:\n",
        "#     print(\"\\nExample batch from DataLoader:\")\n",
        "#     print(\"Texts batch shape:\", texts.shape)\n",
        "#     print(\"Labels batch shape:\", labels.shape)\n",
        "#     print(\"First text in batch (padded sequence):\", texts[0])\n",
        "#     print(\"Corresponding label:\", labels[0])\n",
        "#     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjDoTraIb3uK",
        "outputId": "8cc1cf06-91e7-47d9-f608-0e6c93e3a740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 9482\n",
            "Test: 2371\n",
            "149\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PyTorch Models (RNN, GRU, LSTM, BiLSTM) Defination ---\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        hidden_last_layer = hidden[-1,:,:]\n",
        "        return self.fc(hidden_last_layer)\n",
        "\n",
        "class SentimentGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        hidden_last_layer = hidden[-1,:,:]\n",
        "        return self.fc(hidden_last_layer)\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        hidden_last_layer = hidden[-1,:,:]\n",
        "        return self.fc(hidden_last_layer)\n",
        "\n",
        "class SentimentBiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # bidirectional=True means hidden_dim will be multiplied by 2 in the output\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        # Output from bidirectional LSTM will be hidden_dim * 2\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        hidden_forward = hidden[-2, :, :] # Second to last layer for forward\n",
        "        hidden_backward = hidden[-1, :, :] # Last layer for backward\n",
        "        hidden_combined = torch.cat((hidden_forward, hidden_backward), dim=1)\n",
        "        # hidden_combined = [batch size, hidden dim * 2]\n",
        "\n",
        "        return self.fc(hidden_combined)"
      ],
      "metadata": {
        "id": "Nf-WTooeb884"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training and Evaluation Functions ---\n",
        "\n",
        "def train_model(model, iterator, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train() # Set model to training mode\n",
        "\n",
        "    for texts, labels in iterator:\n",
        "        texts = texts.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "        predictions = model(texts).squeeze(1)\n",
        "\n",
        "        if model.fc.out_features == 1:\n",
        "            labels = labels.float()\n",
        "\n",
        "        loss = criterion(predictions, labels)\n",
        "        # For multi-class, using argmax\n",
        "        if model.fc.out_features > 1:\n",
        "            acc = (predictions.argmax(dim=1) == labels).float().mean()\n",
        "        else: # Binary classification\n",
        "            # Apply sigmoid and round for accuracy calculation\n",
        "            rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "            acc = (rounded_predictions == labels).float().mean()\n",
        "\n",
        "        loss.backward() # Backpropagate\n",
        "        optimizer.step() # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate_model(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in iterator:\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions = model(texts).squeeze(1)\n",
        "\n",
        "            if model.fc.out_features == 1:\n",
        "                labels = labels.float()\n",
        "\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            if model.fc.out_features > 1:\n",
        "                acc = (predictions.argmax(dim=1) == labels).float().mean()\n",
        "            else:\n",
        "                rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "                acc = (rounded_predictions == labels).float().mean()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "MRGCEnKzcEQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Initiate, Training, and Testing ---\n",
        "\n",
        "# Hyperparameters\n",
        "VOCAB_SIZE = len(vocab_to_int)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = len(unique_sentiments)\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "N_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "id": "yy6LklS4pURz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train and Evaluate RNN ---\n",
        "print(\"\\n--- Training RNN Model ---\")\n",
        "model_rnn = SentimentRNN(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
        "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr=LEARNING_RATE)\n",
        "# CrossEntropyLoss for multi-class classification\n",
        "criterion_rnn = nn.CrossEntropyLoss() if OUTPUT_DIM > 1 else nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_valid_loss_rnn = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_rnn, train_loader, optimizer_rnn, criterion_rnn, device)\n",
        "    valid_loss, valid_acc = evaluate_model(model_rnn, test_loader, criterion_rnn, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss_rnn:\n",
        "        best_valid_loss_rnn = valid_loss\n",
        "        torch.save(model_rnn.state_dict(), 'rnn_model.pt')\n",
        "\n",
        "    print(f'RNN Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "# Load model and evaluate on test set\n",
        "model_rnn.load_state_dict(torch.load('rnn_model.pt'))\n",
        "test_loss_rnn, test_acc_rnn = evaluate_model(model_rnn, test_loader, criterion_rnn, device)\n",
        "print(f'RNN Test Loss: {test_loss_rnn:.3f} | RNN Test Acc: {test_acc_rnn*100:.2f}%')\n",
        "results['RNN'] = {'Test Loss': test_loss_rnn, 'Test Accuracy': test_acc_rnn}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVuDtdpTcOK-",
        "outputId": "c62469d1-6d48-4063-cd02-e452a48d7aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 6: Instantiating, Training, and Testing Models...\n",
            "Using device: cpu\n",
            "\n",
            "--- Training RNN Model ---\n",
            "RNN Epoch: 01 | Train Loss: 1.076 | Train Acc: 40.19% | Valid Loss: 1.055 | Valid Acc: 42.50%\n",
            "RNN Epoch: 02 | Train Loss: 1.055 | Train Acc: 41.80% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "RNN Epoch: 03 | Train Loss: 1.056 | Train Acc: 40.12% | Valid Loss: 1.050 | Valid Acc: 42.50%\n",
            "RNN Epoch: 04 | Train Loss: 1.053 | Train Acc: 40.85% | Valid Loss: 1.052 | Valid Acc: 42.50%\n",
            "RNN Epoch: 05 | Train Loss: 1.053 | Train Acc: 40.01% | Valid Loss: 1.058 | Valid Acc: 42.50%\n",
            "RNN Epoch: 06 | Train Loss: 1.058 | Train Acc: 39.78% | Valid Loss: 1.087 | Valid Acc: 38.24%\n",
            "RNN Epoch: 07 | Train Loss: 1.052 | Train Acc: 41.07% | Valid Loss: 1.058 | Valid Acc: 38.24%\n",
            "RNN Epoch: 08 | Train Loss: 1.055 | Train Acc: 41.00% | Valid Loss: 1.052 | Valid Acc: 38.24%\n",
            "RNN Epoch: 09 | Train Loss: 1.052 | Train Acc: 41.17% | Valid Loss: 1.068 | Valid Acc: 42.50%\n",
            "RNN Epoch: 10 | Train Loss: 1.055 | Train Acc: 40.60% | Valid Loss: 1.073 | Valid Acc: 38.24%\n",
            "RNN Test Loss: 1.049 | RNN Test Acc: 42.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train and Evaluate GRU ---\n",
        "print(\"\\n--- Training GRU Model ---\")\n",
        "model_gru = SentimentGRU(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
        "optimizer_gru = optim.Adam(model_gru.parameters(), lr=LEARNING_RATE)\n",
        "criterion_gru = nn.CrossEntropyLoss() if OUTPUT_DIM > 1 else nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_valid_loss_gru = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_gru, train_loader, optimizer_gru, criterion_gru, device)\n",
        "    valid_loss, valid_acc = evaluate_model(model_gru, test_loader, criterion_gru, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss_gru:\n",
        "        best_valid_loss_gru = valid_loss\n",
        "        torch.save(model_gru.state_dict(), 'gru_model.pt')\n",
        "\n",
        "    print(f'GRU Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "model_gru.load_state_dict(torch.load('gru_model.pt'))\n",
        "test_loss_gru, test_acc_gru = evaluate_model(model_gru, test_loader, criterion_gru, device)\n",
        "print(f'GRU Test Loss: {test_loss_gru:.3f} | GRU Test Acc: {test_acc_gru*100:.2f}%')\n",
        "results['GRU'] = {'Test Loss': test_loss_gru, 'Test Accuracy': test_acc_gru}\n",
        "\n",
        "\n",
        "# --- Train and Evaluate LSTM ---\n",
        "print(\"\\n--- Training LSTM Model ---\")\n",
        "model_lstm = SentimentLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
        "optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=LEARNING_RATE)\n",
        "criterion_lstm = nn.CrossEntropyLoss() if OUTPUT_DIM > 1 else nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_valid_loss_lstm = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_lstm, train_loader, optimizer_lstm, criterion_lstm, device)\n",
        "    valid_loss, valid_acc = evaluate_model(model_lstm, test_loader, criterion_lstm, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss_lstm:\n",
        "        best_valid_loss_lstm = valid_loss\n",
        "        torch.save(model_lstm.state_dict(), 'lstm_model.pt')\n",
        "\n",
        "    print(f'LSTM Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "model_lstm.load_state_dict(torch.load('lstm_model.pt'))\n",
        "test_loss_lstm, test_acc_lstm = evaluate_model(model_lstm, test_loader, criterion_lstm, device)\n",
        "print(f'LSTM Test Loss: {test_loss_lstm:.3f} | LSTM Test Acc: {test_acc_lstm*100:.2f}%')\n",
        "results['LSTM'] = {'Test Loss': test_loss_lstm, 'Test Accuracy': test_acc_lstm}\n",
        "\n",
        "\n",
        "# --- Train and Evaluate BiLSTM ---\n",
        "print(\"\\n--- Training BiLSTM Model ---\")\n",
        "model_bilstm = SentimentBiLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
        "optimizer_bilstm = optim.Adam(model_bilstm.parameters(), lr=LEARNING_RATE)\n",
        "criterion_bilstm = nn.CrossEntropyLoss() if OUTPUT_DIM > 1 else nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_valid_loss_bilstm = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_bilstm, train_loader, optimizer_bilstm, criterion_bilstm, device)\n",
        "    valid_loss, valid_acc = evaluate_model(model_bilstm, test_loader, criterion_bilstm, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss_bilstm:\n",
        "        best_valid_loss_bilstm = valid_loss\n",
        "        torch.save(model_bilstm.state_dict(), 'bilstm_model.pt')\n",
        "\n",
        "    print(f'BiLSTM Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "model_bilstm.load_state_dict(torch.load('bilstm_model.pt'))\n",
        "test_loss_bilstm, test_acc_bilstm = evaluate_model(model_bilstm, test_loader, criterion_bilstm, device)\n",
        "print(f'BiLSTM Test Loss: {test_loss_bilstm:.3f} | BiLSTM Test Acc: {test_acc_bilstm*100:.2f}%')\n",
        "results['BiLSTM'] = {'Test Loss': test_loss_bilstm, 'Test Accuracy': test_acc_bilstm}\n",
        "\n",
        "print(\"\\n--- All Models Training and Testing Complete ---\")\n",
        "print(\"\\nSummary of Test Results:\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  Test Loss: {metrics['Test Loss']:.3f}\")\n",
        "    print(f\"  Test Accuracy: {metrics['Test Accuracy']*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bghFn-qxcWAu",
        "outputId": "bb5dccaf-c90c-4275-9a45-f2176c71d91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training GRU Model ---\n",
            "GRU Epoch: 01 | Train Loss: 1.056 | Train Acc: 40.85% | Valid Loss: 1.058 | Valid Acc: 38.24%\n",
            "GRU Epoch: 02 | Train Loss: 1.054 | Train Acc: 41.07% | Valid Loss: 1.057 | Valid Acc: 42.50%\n",
            "GRU Epoch: 03 | Train Loss: 1.052 | Train Acc: 40.38% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "GRU Epoch: 04 | Train Loss: 1.049 | Train Acc: 41.87% | Valid Loss: 1.054 | Valid Acc: 38.24%\n",
            "GRU Epoch: 05 | Train Loss: 1.048 | Train Acc: 41.95% | Valid Loss: 1.039 | Valid Acc: 46.07%\n",
            "GRU Epoch: 06 | Train Loss: 1.027 | Train Acc: 47.80% | Valid Loss: 0.990 | Valid Acc: 52.78%\n",
            "GRU Epoch: 07 | Train Loss: 0.981 | Train Acc: 53.91% | Valid Loss: 0.952 | Valid Acc: 57.68%\n",
            "GRU Epoch: 08 | Train Loss: 0.921 | Train Acc: 58.60% | Valid Loss: 0.910 | Valid Acc: 60.18%\n",
            "GRU Epoch: 09 | Train Loss: 0.868 | Train Acc: 62.08% | Valid Loss: 0.893 | Valid Acc: 60.59%\n",
            "GRU Epoch: 10 | Train Loss: 0.831 | Train Acc: 63.95% | Valid Loss: 0.901 | Valid Acc: 61.75%\n",
            "GRU Test Loss: 0.893 | GRU Test Acc: 60.59%\n",
            "\n",
            "--- Training LSTM Model ---\n",
            "LSTM Epoch: 01 | Train Loss: 1.050 | Train Acc: 41.43% | Valid Loss: 1.051 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 02 | Train Loss: 1.049 | Train Acc: 40.75% | Valid Loss: 1.050 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 03 | Train Loss: 1.049 | Train Acc: 41.42% | Valid Loss: 1.051 | Valid Acc: 38.24%\n",
            "LSTM Epoch: 04 | Train Loss: 1.048 | Train Acc: 41.39% | Valid Loss: 1.050 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 05 | Train Loss: 1.048 | Train Acc: 41.78% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 06 | Train Loss: 1.048 | Train Acc: 41.55% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 07 | Train Loss: 1.048 | Train Acc: 41.65% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 08 | Train Loss: 1.048 | Train Acc: 41.39% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 09 | Train Loss: 1.048 | Train Acc: 41.68% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "LSTM Epoch: 10 | Train Loss: 1.048 | Train Acc: 41.97% | Valid Loss: 1.049 | Valid Acc: 42.50%\n",
            "LSTM Test Loss: 1.049 | LSTM Test Acc: 42.50%\n",
            "\n",
            "--- Training BiLSTM Model ---\n",
            "BiLSTM Epoch: 01 | Train Loss: 1.041 | Train Acc: 44.19% | Valid Loss: 1.021 | Valid Acc: 47.59%\n",
            "BiLSTM Epoch: 02 | Train Loss: 1.016 | Train Acc: 49.15% | Valid Loss: 0.991 | Valid Acc: 52.19%\n",
            "BiLSTM Epoch: 03 | Train Loss: 0.983 | Train Acc: 52.83% | Valid Loss: 0.980 | Valid Acc: 54.58%\n",
            "BiLSTM Epoch: 04 | Train Loss: 0.950 | Train Acc: 55.83% | Valid Loss: 0.940 | Valid Acc: 55.81%\n",
            "BiLSTM Epoch: 05 | Train Loss: 0.902 | Train Acc: 59.71% | Valid Loss: 0.986 | Valid Acc: 56.92%\n",
            "BiLSTM Epoch: 06 | Train Loss: 0.856 | Train Acc: 62.58% | Valid Loss: 0.928 | Valid Acc: 59.43%\n",
            "BiLSTM Epoch: 07 | Train Loss: 0.822 | Train Acc: 63.99% | Valid Loss: 0.951 | Valid Acc: 60.05%\n",
            "BiLSTM Epoch: 08 | Train Loss: 0.766 | Train Acc: 67.11% | Valid Loss: 0.938 | Valid Acc: 61.09%\n",
            "BiLSTM Epoch: 09 | Train Loss: 0.734 | Train Acc: 68.72% | Valid Loss: 0.899 | Valid Acc: 62.03%\n",
            "BiLSTM Epoch: 10 | Train Loss: 0.701 | Train Acc: 70.41% | Valid Loss: 0.952 | Valid Acc: 62.36%\n",
            "BiLSTM Test Loss: 0.899 | BiLSTM Test Acc: 62.03%\n",
            "\n",
            "--- All Models Training and Testing Complete ---\n",
            "\n",
            "Summary of Test Results:\n",
            "RNN:\n",
            "  Test Loss: 1.049\n",
            "  Test Accuracy: 42.50%\n",
            "GRU:\n",
            "  Test Loss: 0.893\n",
            "  Test Accuracy: 60.59%\n",
            "LSTM:\n",
            "  Test Loss: 1.049\n",
            "  Test Accuracy: 42.50%\n",
            "BiLSTM:\n",
            "  Test Loss: 0.899\n",
            "  Test Accuracy: 62.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prediction Function ---\n",
        "\n",
        "def predict_sentiment(model, sentence, vocab_to_int, max_seq_len, pad_token, device, int_to_sentiment):\n",
        "    model.eval()\n",
        "    preprocessed_sentence = preprocess_text(sentence)\n",
        "    encoded_sentence = text_to_sequence(preprocessed_sentence, vocab_to_int)\n",
        "    padded_sentence = pad_sequence(encoded_sentence, max_seq_len, pad_token)\n",
        "\n",
        "    # Converting to tensor and add batch dimension\n",
        "    tensor_sentence = torch.tensor(padded_sentence, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(tensor_sentence)\n",
        "\n",
        "        if model.fc.out_features == 1: # Binary classification\n",
        "            probability = torch.sigmoid(prediction).item()\n",
        "            predicted_class = 1 if probability >= 0.5 else 0\n",
        "            sentiment = int_to_sentiment[predicted_class]\n",
        "            return sentiment, probability\n",
        "        else: # Multi-class classification\n",
        "            probabilities = torch.softmax(prediction, dim=1)\n",
        "            predicted_class = probabilities.argmax(dim=1).item()\n",
        "            sentiment = int_to_sentiment[predicted_class]\n",
        "            return sentiment, probabilities[0][predicted_class].item()\n",
        "\n",
        "print(\"\\n--- Example Sentiment Prediction ---\")\n",
        "# Loading the best model for prediction\n",
        "# model_bilstm.load_state_dict(torch.load('bilstm_model.pt'))\n",
        "model_gru.load_state_dict(torch.load('gru_model.pt'))\n",
        "\n",
        "test_sentences = [\n",
        "    \"The service was terrible and the food was cold.\",\n",
        "    \"It's an okay product, nothing special.\",\n",
        "    \"I am so happy with this purchase.\",\n",
        "    \"What a waste of time and money.\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    predicted_sentiment, confidence = predict_sentiment(\n",
        "        model_bilstm, sentence, vocab_to_int, max_seq_len, vocab_to_int['<PAD>'], device, int_to_sentiment\n",
        "    )\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Predicted Sentiment: {predicted_sentiment} (Confidence: {confidence:.4f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3j0Q9kTclrQ",
        "outputId": "cae91829-1b05-4b3c-df12-8f2ebd5ba61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example Sentiment Prediction ---\n",
            "Sentence: 'The service was terrible and the food was cold.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.8301)\n",
            "\n",
            "Sentence: 'It's an okay product, nothing special.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.7967)\n",
            "\n",
            "Sentence: 'I am so happy with this purchase.'\n",
            "Predicted Sentiment: POSITIVE (Confidence: 0.4963)\n",
            "\n",
            "Sentence: 'What a waste of time and money.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.8378)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def get_predictions(model, iterator, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in iterator:\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions = model(texts).squeeze(1)\n",
        "\n",
        "            if model.fc.out_features > 1: # Multi-class\n",
        "                predicted_classes = predictions.argmax(dim=1)\n",
        "            else: # Binary\n",
        "                predicted_classes = torch.round(torch.sigmoid(predictions))\n",
        "\n",
        "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return np.array(all_labels), np.array(all_predictions)\n",
        "\n",
        "model_to_evaluate = model_bilstm # Choosing the model from four\n",
        "\n",
        "true_labels, predicted_labels = get_predictions(model_to_evaluate, test_loader, device)\n",
        "\n",
        "# Computing confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=sorted(unique_sentiments),\n",
        "            yticklabels=sorted(unique_sentiments))\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(f'Confusion Matrix for {model_to_evaluate.__class__.__name__}')\n",
        "plt.show()\n",
        "\n",
        "# Display normalized confusion matrix\n",
        "# cm_normalized = confusion_matrix(true_labels, predicted_labels, normalize='true')\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "#             xticklabels=sorted(unique_sentiments),\n",
        "#             yticklabels=sorted(unique_sentiments))\n",
        "# plt.xlabel('Predicted Label')\n",
        "# plt.ylabel('True Label')\n",
        "# plt.title(f'Normalized Confusion Matrix for {model_to_evaluate.__class__.__name__}')\n",
        "# plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "LPDpZl10szi3",
        "outputId": "f0828938-aac1-41f4-bc19-9c001d756f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TextCNN Model ---\n",
        "class SentimentTextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Define a convolutional layer for each filter size\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embedding_dim))\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text = [batch size, seq len]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, seq len, embedding dim]\n",
        "\n",
        "        # Add a channel dimension for Conv2d\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        # embedded = [batch size, 1, seq len, embedding dim]\n",
        "\n",
        "        conved = [torch.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        # conved_n = [batch size, n_filters, (seq len - filter_size + 1)]\n",
        "\n",
        "        pooled = [torch.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        # pooled_n = [batch size, n_filters]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "oL7iem35vkyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Hyperparameters\n",
        "VOCAB_SIZE = len(vocab_to_int)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 512 # Used for RNN/GRU/LSTM/BiLSTM\n",
        "OUTPUT_DIM = len(unique_sentiments)\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "N_EPOCHS = 30\n",
        "LEARNING_RATE = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "# TextCNN specific hyperparameters\n",
        "N_FILTERS = 100 # Number of filters for each filter size\n",
        "FILTER_SIZES = [2, 3, 4] # Filter sizes (n-grams to capture)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "# --- Train and Evaluate TextCNN ---\n",
        "print(\"\\n--- Training TextCNN Model (New) ---\")\n",
        "model_cnn = SentimentTextCNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT).to(device)\n",
        "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=LEARNING_RATE)\n",
        "criterion_cnn = nn.CrossEntropyLoss() if OUTPUT_DIM > 1 else nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_valid_loss_cnn = float('inf')\n",
        "epochs_no_improve_cnn = 0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_model(model_cnn, train_loader, optimizer_cnn, criterion_cnn, device)\n",
        "    valid_loss, valid_acc = evaluate_model(model_cnn, test_loader, criterion_cnn, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss_cnn:\n",
        "        best_valid_loss_cnn = valid_loss\n",
        "        torch.save(model_cnn.state_dict(), 'cnn_model_enhanced.pt')\n",
        "        epochs_no_improve_cnn = 0\n",
        "    else:\n",
        "        epochs_no_improve_cnn += 1\n",
        "\n",
        "    print(f'TextCNN Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    if epochs_no_improve_cnn == PATIENCE:\n",
        "        print(f'Early stopping triggered for TextCNN at epoch {epoch+1}.')\n",
        "        break\n",
        "\n",
        "model_cnn.load_state_dict(torch.load('cnn_model_enhanced.pt'))\n",
        "test_loss_cnn, test_acc_cnn = evaluate_model(model_cnn, test_loader, criterion_cnn, device)\n",
        "print(f'TextCNN Test Loss: {test_loss_cnn:.3f} | TextCNN Test Acc: {test_acc_cnn*100:.2f}%')\n",
        "results['TextCNN (Enhanced)'] = {'Test Loss': test_loss_cnn, 'Test Accuracy': test_acc_cnn}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spc1Afy_x-iM",
        "outputId": "003d0f18-137b-4d17-999e-94133e4a32bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Training TextCNN Model (New) ---\n",
            "TextCNN Epoch: 01 | Train Loss: 1.090 | Train Acc: 46.24% | Valid Loss: 0.975 | Valid Acc: 52.56%\n",
            "TextCNN Epoch: 02 | Train Loss: 0.905 | Train Acc: 58.46% | Valid Loss: 0.952 | Valid Acc: 58.61%\n",
            "TextCNN Epoch: 03 | Train Loss: 0.769 | Train Acc: 66.71% | Valid Loss: 0.919 | Valid Acc: 58.85%\n",
            "TextCNN Epoch: 04 | Train Loss: 0.636 | Train Acc: 73.92% | Valid Loss: 0.901 | Valid Acc: 60.39%\n",
            "TextCNN Epoch: 05 | Train Loss: 0.504 | Train Acc: 79.91% | Valid Loss: 0.965 | Valid Acc: 62.12%\n",
            "TextCNN Epoch: 06 | Train Loss: 0.389 | Train Acc: 85.51% | Valid Loss: 1.036 | Valid Acc: 62.49%\n",
            "TextCNN Epoch: 07 | Train Loss: 0.292 | Train Acc: 89.67% | Valid Loss: 1.054 | Valid Acc: 61.75%\n",
            "TextCNN Epoch: 08 | Train Loss: 0.210 | Train Acc: 93.09% | Valid Loss: 1.148 | Valid Acc: 60.72%\n",
            "TextCNN Epoch: 09 | Train Loss: 0.162 | Train Acc: 94.61% | Valid Loss: 1.252 | Valid Acc: 62.49%\n",
            "Early stopping triggered for TextCNN at epoch 9.\n",
            "TextCNN Test Loss: 0.901 | TextCNN Test Acc: 60.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prediction Function ---\n",
        "\n",
        "def predict_sentiment(model, sentence, vocab_to_int, max_seq_len, pad_token, device, int_to_sentiment):\n",
        "    model.eval()\n",
        "    preprocessed_sentence = preprocess_text(sentence)\n",
        "    encoded_sentence = text_to_sequence(preprocessed_sentence, vocab_to_int)\n",
        "    padded_sentence = pad_sequence(encoded_sentence, max_seq_len, pad_token)\n",
        "\n",
        "    # Converting to tensor and add batch dimension\n",
        "    tensor_sentence = torch.tensor(padded_sentence, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(tensor_sentence)\n",
        "\n",
        "        if model.fc.out_features == 1: # Binary classification\n",
        "            probability = torch.sigmoid(prediction).item()\n",
        "            predicted_class = 1 if probability >= 0.5 else 0\n",
        "            sentiment = int_to_sentiment[predicted_class]\n",
        "            return sentiment, probability\n",
        "        else: # Multi-class classification\n",
        "            probabilities = torch.softmax(prediction, dim=1)\n",
        "            predicted_class = probabilities.argmax(dim=1).item()\n",
        "            sentiment = int_to_sentiment[predicted_class]\n",
        "            return sentiment, probabilities[0][predicted_class].item()\n",
        "\n",
        "print(\"\\n--- Example Sentiment Prediction ---\")\n",
        "# Loading the best model for prediction\n",
        "# model_bilstm.load_state_dict(torch.load('bilstm_model.pt'))\n",
        "model_cnn.load_state_dict(torch.load('cnn_model_enhanced.pt'))\n",
        "\n",
        "test_sentences = [\n",
        "    \"The service was terrible and the food was cold.\",\n",
        "    \"It's an okay product, nothing special.\",\n",
        "    \"I am so happy with this purchase.\",\n",
        "    \"What a waste of time and money.\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    predicted_sentiment, confidence = predict_sentiment(\n",
        "        model_bilstm, sentence, vocab_to_int, max_seq_len, vocab_to_int['<PAD>'], device, int_to_sentiment\n",
        "    )\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"Predicted Sentiment: {predicted_sentiment} (Confidence: {confidence:.4f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLbSMWf4yUzE",
        "outputId": "5927b6c4-1eca-4ea7-d134-9a9b9d8ede9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example Sentiment Prediction ---\n",
            "Sentence: 'The movie was fantastic and the actors were amazing.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.7713)\n",
            "\n",
            "Sentence: 'The service was terrible and the food was cold.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.8301)\n",
            "\n",
            "Sentence: 'It's an okay product, nothing special.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.7967)\n",
            "\n",
            "Sentence: 'I am so happy with this purchase.'\n",
            "Predicted Sentiment: POSITIVE (Confidence: 0.4963)\n",
            "\n",
            "Sentence: 'What a waste of time and money.'\n",
            "Predicted Sentiment: NEGATIVE (Confidence: 0.8378)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9fQs2702cgD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}